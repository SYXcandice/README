{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c3be693",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8e59e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import copy\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from PIL import Image, ImageChops\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import shutil\n",
    "from shutil import copy2\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24a10002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#下载图片\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3ca6f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cifar-10-batches-py/data_batch_1 is loading...\n",
      "./cifar-10-batches-py/data_batch_1 loaded.\n",
      "./cifar-10-batches-py/data_batch_2 is loading...\n",
      "./cifar-10-batches-py/data_batch_2 loaded.\n",
      "./cifar-10-batches-py/data_batch_3 is loading...\n",
      "./cifar-10-batches-py/data_batch_3 loaded.\n",
      "./cifar-10-batches-py/data_batch_4 is loading...\n",
      "./cifar-10-batches-py/data_batch_4 loaded.\n",
      "./cifar-10-batches-py/data_batch_5 is loading...\n",
      "./cifar-10-batches-py/data_batch_5 loaded.\n",
      "test_batch is loading...\n",
      "test_batch loaded.\n"
     ]
    }
   ],
   "source": [
    "#将 cifar 里的所有数据扒出来保存为图片文件\n",
    "\n",
    "# 解压缩，返回解压后的字典\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "def cifar10_to_images():\n",
    "    tar_dir='./cifar-10-batches-py/' #原始数据库目录\n",
    "    train_root_dir='./cifar10/train/' #图片保存目录\n",
    "    test_root_dir='./cifar10/test/'\n",
    "    if not os.path.exists(train_root_dir):\n",
    "        os.makedirs(train_root_dir)\n",
    "    if not os.path.exists(test_root_dir):\n",
    "        os.makedirs(test_root_dir)\n",
    "    # 生成训练集图片，如果需要png格式，只需要改图片后缀名即可。\n",
    "    label_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"dear\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "    for j in range(1, 6):\n",
    "        dataName = tar_dir+\"data_batch_\" + str(j) \n",
    "        Xtr = unpickle(dataName)\n",
    "        print(dataName + \" is loading...\")\n",
    "\n",
    "        for i in range(0, 10000):\n",
    "            img = np.reshape(Xtr['data'][i], (3, 32, 32))  # Xtr['data']为图片二进制数据\n",
    "            img = img.transpose(1, 2, 0)  # 读取image\n",
    "            picName = train_root_dir + str(Xtr['labels'][i])+ '_' + label_names[Xtr['labels'][i]]+'_'+ str(i + (j - 1)*10000)+'.jpg'  # label+class+index\n",
    "            cv2.imwrite(picName, img)\n",
    "        print(dataName + \" loaded.\")\n",
    "\n",
    "    print(\"test_batch is loading...\")\n",
    " \n",
    "    # 生成测试集图片\n",
    "    testXtr = unpickle(tar_dir+\"test_batch\")\n",
    "    for i in range(0, 10000):\n",
    "        img = np.reshape(testXtr['data'][i], (3, 32, 32))\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        picName = test_root_dir + str(testXtr['labels'][i])+ '_' + label_names[testXtr['labels'][i]]+'_' + str(i) + '.jpg'\n",
    "        cv2.imwrite(picName, img)\n",
    "    print(\"test_batch loaded.\")\n",
    "    \n",
    "cifar10_to_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5f6cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取并且反转\n",
    "\n",
    "def read_directory(directory_name):\n",
    "# this loop is for read each image in this foder,directory_name is the foder name with images.\n",
    "    for filename in os.listdir(r\"./\"+directory_name):\n",
    "        #读取图片\n",
    "        fname = filename\n",
    "        img = Image.open('./data/' + filename)\n",
    "        img_inverted = ImageChops.invert(img)\n",
    "        img_inverted.save('./data_convert/' + filename)\n",
    "\n",
    "read_directory('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6497015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加高斯模糊\n",
    "\n",
    "kernel_size = (3, 3)\n",
    "sigma = 1.5\n",
    "\n",
    "def read_directory(directory_name):\n",
    "# this loop is for read each image in this foder,directory_name is the foder name with images.\n",
    "    for filename in os.listdir(r\"./\"+directory_name):\n",
    "        #读取图片\n",
    "        \n",
    "        imgName = filename\n",
    "        img = cv2.imread('./data_convert/'+imgName)\n",
    "        img = cv2.GaussianBlur(img, kernel_size, sigma)\n",
    "        new_imgName = imgName\n",
    "        cv2.imwrite('./data_convert_mohu/'+new_imgName, img)\n",
    "\n",
    "read_directory('./data_convert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19b88193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加满足高斯分布的白噪声\n",
    "\n",
    "def gasuss_noise(image, mean=0, var=0.001):\n",
    " \n",
    "    '''\n",
    "        添加高斯噪声\n",
    "        mean : 均值\n",
    "        var : 方差\n",
    "    '''\n",
    " \n",
    "    image = np.array(image/255, dtype=float)\n",
    "    noise = np.random.normal(mean, var ** 0.5, image.shape)\n",
    "    out = image + noise\n",
    " \n",
    "    '''\n",
    "        将值限制在(-1/0,1)间，然后乘255恢复\n",
    "    '''\n",
    "\n",
    "    if out.min() < 0:\n",
    "        low_clip = -1.\n",
    "    else:\n",
    "        low_clip = 0.\n",
    " \n",
    "    out = np.clip(out, low_clip, 1.0)\n",
    "    out = np.uint8(out*255)\n",
    "    return out\n",
    "\n",
    "def read_directory(directory_name):\n",
    "# this loop is for read each image in this foder,directory_name is the foder name with images.\n",
    "    for filename in os.listdir(r\"./\"+directory_name):\n",
    "        #读取图片\n",
    "        imgName = filename\n",
    "        img = cv2.imread('./data_convert_mohu/'+imgName)\n",
    "        # 添加高斯噪声，均值为0，方差为0.001\n",
    "        out2 = gasuss_noise(img, mean=0, var=0.001)\n",
    "        new_imgName = imgName\n",
    "        cv2.imwrite('./data_convert_mohu_baizao/'+new_imgName, out2)\n",
    "\n",
    "read_directory('./data_convert_mohu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "332a4e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#求 x 和 y 方向图像梯度\n",
    "\n",
    "# Scharr算子实现梯度计算\n",
    "def Scharr_demo(image):\n",
    "    # x 方向梯度\n",
    "    image_grad_x = cv2.Scharr(image, cv2.CV_32F, 1, 0)\n",
    "    # y 方向梯度\n",
    "    image_grad_y = cv2.Scharr(image, cv2.CV_32F, 0, 1)\n",
    "    # 分别求绝对值并转化为8位的图像上，这样做方便显示\n",
    "    image_gradx = cv2.convertScaleAbs(image_grad_x) \n",
    "    image_grady = cv2.convertScaleAbs(image_grad_y)\n",
    "#     # 显示两个方向图像\n",
    "#     cv2.imshow(\"image_gradient-x\", image_gradx)\n",
    "#     cv2.imshow(\"image_gradient-y\", image_grady)\n",
    "    #两个方向梯度的叠加，权重各自一半\n",
    "    image_gradxy = cv2.addWeighted(image_gradx, 0.5, image_grady, 0.5, 0)\n",
    "#     cv2.imshow(\"image_gradient\", image_gradxy)\n",
    "    return image_gradxy\n",
    "\n",
    "def read_directory(directory_name):\n",
    "# this loop is for read each image in this foder,directory_name is the foder name with images.\n",
    "    for filename in os.listdir(r\"./\"+directory_name):\n",
    "        #读取图片\n",
    "        imgName = filename\n",
    "        img = cv2.imread('./data_convert_mohu_baizao/'+imgName)\n",
    "        out = Scharr_demo(img)\n",
    "        new_imgName = imgName\n",
    "        cv2.imwrite('./data_convert_mohu_baizao_tidu/'+new_imgName, out)\n",
    "\n",
    "read_directory('./data_convert_mohu_baizao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98eb1ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_all_data: 58994\n"
     ]
    }
   ],
   "source": [
    "#将扒出来的图片按 8:1:1 分成训练集，验证集和测试集。\n",
    "#分别保存在 train，validation， test 三个 folder 中。\n",
    "\n",
    "datadir_normal = \"./data_convert_mohu_baizao_tidu/\"\n",
    "\n",
    "all_data = os.listdir(datadir_normal)#（图片文件夹）\n",
    "num_all_data = len(all_data)\n",
    "print( \"num_all_data: \" + str(num_all_data) )\n",
    "index_list = list(range(num_all_data))\n",
    "#print(index_list)\n",
    "random.shuffle(index_list)\n",
    "num = 0\n",
    "\n",
    "trainDir = \"./811/train/\"#（将训练集放在这个文件夹下）\n",
    "if not os.path.exists(trainDir):\n",
    "    os.mkdir(trainDir)\n",
    "        \n",
    "validDir = './811/validation/'#（将验证集放在这个文件夹下）\n",
    "if not os.path.exists(validDir):\n",
    "    os.mkdir(validDir)\n",
    "        \n",
    "testDir = './811/test/'#（将测试集放在这个文件夹下）        \n",
    "if not os.path.exists(testDir):\n",
    "    os.mkdir(testDir)\n",
    "        \n",
    "for i in index_list:\n",
    "    fileName = os.path.join(datadir_normal, all_data[i])\n",
    "    if num < num_all_data*0.8:\n",
    "        #print(str(fileName))\n",
    "        copy2(fileName, trainDir)\n",
    "    elif num>num_all_data*0.8 and num < num_all_data*0.9:\n",
    "        #print(str(fileName))\n",
    "        copy2(fileName, validDir)\n",
    "    else:\n",
    "        copy2(fileName, testDir)\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f53b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('0_airplane_3_反转_高斯模糊_高斯白噪.jpg')\n",
    "# # x 方向梯度\n",
    "# image_grad_x = cv2.Scharr(img, cv2.CV_32F, 1, 0)\n",
    "# # y 方向梯度\n",
    "# image_grad_y = cv2.Scharr(img, cv2.CV_32F, 0, 1)\n",
    "# # 分别求绝对值并转化为8位的图像上，这样做方便显示\n",
    "# image_gradx = cv2.convertScaleAbs(image_grad_x) \n",
    "# image_grady = cv2.convertScaleAbs(image_grad_y)\n",
    "# image_gradxy = cv2.addWeighted(image_gradx, 0.5, image_grady, 0.5, 0)\n",
    "# cv2.imwrite('./x.jpg', image_gradx)\n",
    "# cv2.imwrite('./y.jpg', image_grady)\n",
    "# cv2.imwrite('./xy.jpg', image_gradxy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "af8259ad5c1c9c7a69bd6ea085234cf8fd3a6a37a71ca551828b314c4d89b0ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
